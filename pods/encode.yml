!TransformerTorchEncoder
with:
  pooling_strategy: cls # Works in Docker
  #pooling_strategy: auto # Works on local
  pretrained_model_name_or_path: distilbert-base-cased
  max_length: 96
