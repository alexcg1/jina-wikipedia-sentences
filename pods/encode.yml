!TransformerTorchEncoder
with:
  pooling_strategy: cls # Works in Docker
  pretrained_model_name_or_path: distilbert-base-cased
  max_length: 96
